
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>

<head>
	<title> GRAINS: Generative Recursive Autoencoders for Indoor Scenes </title>
	<link rel="stylesheet" type="text/css" media="screen" href="style.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="iconize.css" />	
</head>


<body>



<div id="paper-title"> <h1> GRAINS: Generative Recursive Autoencoders for Indoor Scenes </h1> </div>
<div id="venue">
	Transaction on Graphics,2018
</div>

<div id="author-list">  
	<a href="https://manyili12345.github.io/"> Manyi Li <sup>1,2</sup> </a>
	<a href="http://www.sfu.ca/~agadipat/"> Akshay Gadi Patil <sup>2</sup> </a>
	<a href="https://kevinkaixu.net/"> Kai Xu <sup>3</sup> </a>
	<a href="https://www.cse.iitb.ac.in/~sidch/"> Siddhartha Chaudhuri <sup>4,5</sup> </a>
	<a href=""> Owais Khan <sup>5</sup> </a>
	<br/>
	<a href="http://www.faculty.idc.ac.il/arik/site/index.asp"> Ariel Shamir <sup>6</sup> </a>
	<a href="http://www.cs.sdu.edu.cn/en/~chtu"> Changhe Tu <sup>1</sup> </a>
	<a href="http://www.cs.sdu.edu.cn/~baoquan/"> Baoquan Chen <sup>7</sup> </a>
	<a href="https://www.cs.tau.ac.il/~dcor/"> Daniel Cohen-Or <sup>8</sup> </a>
	<a href="http://www.cs.sfu.ca/~haoz/"> Hao Zhang <sup>2</sup> </a>
</div>

<div id="author-affiliation">
	<span class="affiliation"> <sup>1</sup> Shandong University </span>
	<span class="affiliation"> <sup>2</sup> Simon Fraser University </span>
	<br/>
	<span class="affiliation"> <sup>3</sup> National University of Defence Technology </span>
	<span class="affiliation"> <sup>4</sup> Adobe Research </span>
	<br/>
	<span class="affiliation"> <sup>5</sup> IIT Bombay </span>
	<span class="affiliation"> <sup>6</sup> The Interdisciplinary Center </span>
	<br/>
	<span class="affiliation"> <sup>7</sup> Peking University </span>
	<span class="affiliation"> <sup>8</sup> Tel-Aviv University </span>
</div>
</br>
</br>
</br>
</br>

<div id="teaser-part">
	<a class="imageLink" href="teaserfig_grains.png"><img id="teaser" src="teaserfig_grains.png" alt="Teaser" /></a>
</div>

<div id="abstract">
	<h2 class="caption"> Abstract </h2>
	<p class="paragraph">  
We present a generative neural network which enables us to generate plausible
3D indoor scenes in large quantities and varieties, easily and highly
efficiently. Our key observation is that indoor scene structures are inherently
hierarchical. Hence, our network is not convolutional; it is a recursive neural
network or RvNN. Using a dataset of annotated scene hierarchies, we train
a variational recursive autoencoder, or RvNN-VAE, which performs scene
object grouping during its encoding phase and scene generation during
decoding. Specifically, a set of encoders are recursively applied to group
3D objects based on support, surround, and co-occurrence relations in a
scene, encoding information about objects&apos spatial properties, semantics, and
their relative positioning with respect to other objects in the hierarchy. By
training a variational autoencoder (VAE), the resulting fixed-length codes
roughly follow a Gaussian distribution. A novel 3D scene can be generated
hierarchically by the decoder from a randomly sampled code from the learned distribution.
We coin our method GRAINS, for Generative Recursive
Autoencoders for INdoor Scenes. We demonstrate the capability of GRAINS
to generate plausible and diverse 3D indoor scenes and compare with existing
methods for 3D scene synthesis. We show applications of GRAINS
including 3D scene modeling from 2D layouts, scene editing, and semantic
scene segmentation via PointNet whose performance is boosted by the large
quantity and variety of 3D scenes generated by our method.


	</p>
</div>

<div id="package">  
	<a id="paper-item" href="https://arxiv.org/pdf/1807.09193.pdf">Pre-print</a>
	<a id="code-item" href="https://github.com/ManyiLi12345/GRAINS">Code</a>
	</br>
	</br>
	Please note that we cannot publicly release the SUNCG dataset as it is licensed. To access this data, please refer to<a href="http://suncg.cs.princeton.edu/">SUNCG website.</a>
	</br>
	</br>
	
</div>



</br>

<div id="bibtex"> 
	<h2 class="caption"> Bibtex </h2>
	<p class="paragraph">
	If you find this work useful for your research, please cite our paper using the Bibtex below:
	</p>
	
	<p>
	@article{li2018grains,</br> 
			title={GRAINS: Generative Recursive Autoencoders for Indoor Scenes}, </br>
			author={Li, Manyi and Gadi Patil, Akshay and Xu, Kai and Chaudhuri, Siddhartha and Khan, Owais and Shamir, Ariel and Tu, Changhe and Chen, Baoquan and Cohen-Or, Daniel and Zhang, Hao}, </br>
			journal={ACM Transactions on Graphics}, </br>
			volume={37}, </br>
			number={}, </br>
			year={2018},</br> 
			publisher={ACM}</br> 
			}
	</p>
</div>
			
<div id="acknowledgement">
	<h2 class="caption"> Acknowledgment </h2>
	<p class="paragraph"> 
	We thank the anonymous reviewers for their valuable comments. This work was supported, in parts, by an NSERC grant (611370), the 973 Program of China under Grant 2015CB352502, key program of NSFC (61332015), NSFC programs (61772318, 61532003, 61572507, 61622212), ISF grant 2366/16, gift funds from Adobe and the China Scholarship Council.
	</p>
</div>



<div id="footer">
	<a href="http://gruvi.cs.sfu.ca/"> <img id="gruvi-logo" src="gruvi_logo.png"/> </a>
	<div>&copy;2018 GrUVi@SFU. All rights reserved.</div>
</div>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-49472186-2', 'auto');
  ga('send', 'pageview');

</script>

</body>


</html>
